{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle \n",
    "from gensim.models import Word2Vec\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt = open('data/nyt/vec.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_lines = [line for line in txt.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "txt_count = int(txt_lines[0].split()[0])\n",
    "vec_dim = int(txt_lines[0].split()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_vec_map = {}\n",
    "for line in txt_lines[1:]:\n",
    "    temp_list = line.split()\n",
    "    word = temp_list[0]\n",
    "    vec = []\n",
    "    for number in temp_list[1:]:\n",
    "        vec.append(float(number))\n",
    "    word_vec_map[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nyt_relation = {}\n",
    "inverse_nyt_rela = {}\n",
    "with open(\"data/nyt/relation2id.txt\", 'r') as f:\n",
    "    for line in f.readlines():\n",
    "        line = line.strip('\\n')\n",
    "        if line[0] == '/':\n",
    "            items = str.split(line, ' ')\n",
    "            nyt_relation[items[1]] = items[0]\n",
    "            inverse_nyt_rela[items[0]] = items[1]\n",
    "        else:\n",
    "            items = str.split(line, ' ')\n",
    "            nyt_relation[items[1]] = items[0]\n",
    "            inverse_nyt_rela[items[0]] = items[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'0': 'NA',\n",
       " '1': '/location/neighborhood/neighborhood_of',\n",
       " '10': '/location/it_region/capital',\n",
       " '11': '/people/family/members',\n",
       " '12': '/location/us_state/capital',\n",
       " '13': '/location/us_county/county_seat',\n",
       " '14': '/people/profession/people_with_this_profession',\n",
       " '15': '/location/br_state/capital',\n",
       " '16': '/location/in_state/legislative_capital',\n",
       " '17': '/sports/sports_team/location',\n",
       " '18': '/people/person/religion',\n",
       " '19': '/location/in_state/judicial_capital',\n",
       " '2': '/location/fr_region/capital',\n",
       " '20': '/business/company_advisor/companies_advised',\n",
       " '21': '/people/family/country',\n",
       " '22': '/time/event/locations',\n",
       " '23': '/business/company/place_founded',\n",
       " '24': '/location/administrative_division/country',\n",
       " '25': '/people/ethnicity/included_in_group',\n",
       " '26': '/location/mx_state/capital',\n",
       " '27': '/location/province/capital',\n",
       " '28': '/people/person/nationality',\n",
       " '29': '/business/person/company',\n",
       " '3': '/location/cn_province/capital',\n",
       " '30': '/business/shopping_center_owner/shopping_centers_owned',\n",
       " '31': '/business/company/advisors',\n",
       " '32': '/business/shopping_center/owner',\n",
       " '33': '/people/person/ethnicity',\n",
       " '34': '/people/deceased_person/place_of_burial',\n",
       " '35': '/people/ethnicity/geographic_distribution',\n",
       " '36': '/people/person/place_lived',\n",
       " '37': '/business/company/major_shareholders',\n",
       " '38': '/broadcast/producer/location',\n",
       " '39': '/broadcast/content/location',\n",
       " '4': '/location/in_state/administrative_capital',\n",
       " '40': '/business/business_location/parent_company',\n",
       " '41': '/location/jp_prefecture/capital',\n",
       " '42': '/film/film/featured_film_locations',\n",
       " '43': '/people/place_of_interment/interred_here',\n",
       " '44': '/location/de_state/capital',\n",
       " '45': '/people/person/profession',\n",
       " '46': '/business/company/locations',\n",
       " '47': '/location/country/capital',\n",
       " '48': '/location/location/contains',\n",
       " '49': '/location/country/administrative_divisions',\n",
       " '5': '/base/locations/countries/states_provinces_within',\n",
       " '50': '/people/person/children',\n",
       " '51': '/film/film_location/featured_in_films',\n",
       " '52': '/film/film_festival/location',\n",
       " '6': '/business/company/founders',\n",
       " '7': '/location/country/languages_spoken',\n",
       " '8': '/people/person/place_of_birth',\n",
       " '9': '/people/deceased_person/place_of_death'}"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyt_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/base/locations/countries/states_provinces_within': '5',\n",
       " '/broadcast/content/location': '39',\n",
       " '/broadcast/producer/location': '38',\n",
       " '/business/business_location/parent_company': '40',\n",
       " '/business/company/advisors': '31',\n",
       " '/business/company/founders': '6',\n",
       " '/business/company/locations': '46',\n",
       " '/business/company/major_shareholders': '37',\n",
       " '/business/company/place_founded': '23',\n",
       " '/business/company_advisor/companies_advised': '20',\n",
       " '/business/person/company': '29',\n",
       " '/business/shopping_center/owner': '32',\n",
       " '/business/shopping_center_owner/shopping_centers_owned': '30',\n",
       " '/film/film/featured_film_locations': '42',\n",
       " '/film/film_festival/location': '52',\n",
       " '/film/film_location/featured_in_films': '51',\n",
       " '/location/administrative_division/country': '24',\n",
       " '/location/br_state/capital': '15',\n",
       " '/location/cn_province/capital': '3',\n",
       " '/location/country/administrative_divisions': '49',\n",
       " '/location/country/capital': '47',\n",
       " '/location/country/languages_spoken': '7',\n",
       " '/location/de_state/capital': '44',\n",
       " '/location/fr_region/capital': '2',\n",
       " '/location/in_state/administrative_capital': '4',\n",
       " '/location/in_state/judicial_capital': '19',\n",
       " '/location/in_state/legislative_capital': '16',\n",
       " '/location/it_region/capital': '10',\n",
       " '/location/jp_prefecture/capital': '41',\n",
       " '/location/location/contains': '48',\n",
       " '/location/mx_state/capital': '26',\n",
       " '/location/neighborhood/neighborhood_of': '1',\n",
       " '/location/province/capital': '27',\n",
       " '/location/us_county/county_seat': '13',\n",
       " '/location/us_state/capital': '12',\n",
       " '/people/deceased_person/place_of_burial': '34',\n",
       " '/people/deceased_person/place_of_death': '9',\n",
       " '/people/ethnicity/geographic_distribution': '35',\n",
       " '/people/ethnicity/included_in_group': '25',\n",
       " '/people/family/country': '21',\n",
       " '/people/family/members': '11',\n",
       " '/people/person/children': '50',\n",
       " '/people/person/ethnicity': '33',\n",
       " '/people/person/nationality': '28',\n",
       " '/people/person/place_lived': '36',\n",
       " '/people/person/place_of_birth': '8',\n",
       " '/people/person/profession': '45',\n",
       " '/people/person/religion': '18',\n",
       " '/people/place_of_interment/interred_here': '43',\n",
       " '/people/profession/people_with_this_profession': '14',\n",
       " '/sports/sports_team/location': '17',\n",
       " '/time/event/locations': '22',\n",
       " 'NA': '0'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_nyt_rela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "common_relation = pickle.load(open('data/common_relations.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NA': [3, 'P0', ['0']],\n",
       " 'capital': [2,\n",
       "  'P36',\n",
       "  ['2', '3', '10', '12', '15', '26', '27', '41', '44', '47']],\n",
       " 'country': [6, 'P17', ['21', '24']],\n",
       " 'founder': [7, 'P112', ['6']],\n",
       " 'location': [8, 'P276', ['17', '22', '38', '39', '46', '52']],\n",
       " 'place of birth': [0, 'P19', ['8']],\n",
       " 'place of burial': [1, 'P119', ['34']],\n",
       " 'place of death': [4, 'P20', ['9']],\n",
       " 'religion': [5, 'P140', ['18']]}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, files):\n",
    "        self.files = files\n",
    " \n",
    "    def __iter__(self):\n",
    "#         for fname in os.listdir(self.dirname):\n",
    "#             for line in open(os.path.join(self.dirname, fname)):\n",
    "#                 yield line.split()\n",
    "        for filename in self.files:\n",
    "            for line in open(filename):\n",
    "                items = line.strip('\\n').split('\\t')\n",
    "                words = items[-1][:-9].split()\n",
    "                words = [word.strip('.') for word in words if len(word) > 0]\n",
    "                yield words\n",
    "\n",
    "def GetEntityPos(entity1, entity2, sentence):\n",
    "    pos_1 = 0\n",
    "    pos_2 = 0\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i] == entity1:\n",
    "            pos_1 = i\n",
    "        if sentence[i] == entity2:\n",
    "            pos_2 = i\n",
    "    pos_first = min(pos_1, pos_2)\n",
    "    pos_second = pos_1 + pos_2 - pos_first\n",
    "    return [pos_first, pos_second]\n",
    "\n",
    "def GetEmbeddingData(entity_1, entity_2, words, max_length, vec_size, pos_size, word_2_vec_model):\n",
    "    word_embedding = np.zeros((max_length, vec_size))\n",
    "    pos_embedding = np.zeros((max_length, pos_size))\n",
    "    (entity_pos_1, entity_pos_2) = GetEntityPos(entity_1, entity_2, words)\n",
    "    pos_embedding[entity_pos_1] = np.ones(pos_size)\n",
    "    pos_embedding[entity_pos_2] = np.ones(pos_size)\n",
    "    for i in range(len(words)):\n",
    "        try:\n",
    "            word_embedding[i] = word_2_vec_model[words[i]]\n",
    "        except:\n",
    "            print(words)\n",
    "    input_embedding = np.concatenate((word_embedding, pos_embedding), axis = 1)\n",
    "    input_embedding = input_embedding.reshape(max_length, -1)\n",
    "    \n",
    "    return input_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_training = True\n",
    "txts = ['data/nyt/train.txt', 'data/nyt/test.txt']\n",
    "if is_training:\n",
    "    \n",
    "    # temp_file = open(wiki_file, 'r')\n",
    "    # temp_file_lines = [line for line in temp_file.readlines()]\n",
    "    sentences = MySentences(txts)\n",
    "    model = gensim.models.Word2Vec(sentences, min_count=1, size = 50)\n",
    "    model.save('Preprocess_model_pkl/nyt_vec_model.pkl')\n",
    "else:\n",
    "    model = gensim.models.Word2Vec.load('Preprocess_model_pkl/nyt_vec_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_txt = open('data/nyt/train.txt', 'r')\n",
    "train_lines = [line for line in train_txt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "570088\n"
     ]
    }
   ],
   "source": [
    "for line in train_lines:\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n",
      "count is:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sun/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:36: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count is:  10000\n",
      "count is:  20000\n",
      "count is:  30000\n",
      "count is:  40000\n",
      "count is:  50000\n",
      "count is:  60000\n",
      "count is:  70000\n",
      "count is:  80000\n",
      "count is:  90000\n",
      "count is:  100000\n",
      "count is:  110000\n",
      "count is:  120000\n",
      "count is:  130000\n",
      "count is:  140000\n",
      "count is:  150000\n",
      "count is:  160000\n",
      "count is:  170000\n",
      "count is:  180000\n",
      "count is:  190000\n",
      "count is:  200000\n",
      "count is:  210000\n",
      "count is:  220000\n",
      "count is:  230000\n",
      "count is:  240000\n",
      "count is:  250000\n",
      "count is:  260000\n",
      "count is:  270000\n",
      "count is:  280000\n",
      "count is:  290000\n",
      "count is:  300000\n",
      "count is:  310000\n",
      "count is:  320000\n",
      "count is:  330000\n",
      "count is:  340000\n",
      "count is:  350000\n",
      "count is:  360000\n",
      "count is:  370000\n",
      "count is:  380000\n",
      "count is:  390000\n",
      "count is:  400000\n",
      "count is:  410000\n",
      "count is:  420000\n",
      "count is:  430000\n",
      "439693\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "relation_labels = []\n",
    "max_length = 100\n",
    "vec_size = 50\n",
    "pos_size = 5\n",
    "train_data = np.zeros((442506, max_length, pos_size+vec_size))\n",
    "for line in train_lines:\n",
    "    flag = 0\n",
    "    items = line.strip('\\n').split('\\t')\n",
    "    if (count%10000) == 0:\n",
    "        print(\"count is: \", count)\n",
    "    if items[4] in inverse_nyt_rela:\n",
    "        relation_name = inverse_nyt_rela[items[4]]\n",
    "    else:\n",
    "        continue\n",
    "    for (key, relation) in common_relation.items():\n",
    "        nyt_list = relation[2]\n",
    "        for nyt_rela in nyt_list:\n",
    "            if relation_name == (nyt_rela):\n",
    "                relation_id = relation[0]\n",
    "                flag = 1\n",
    "                relation_labels.append(relation_id)\n",
    "                break\n",
    "    if flag == 0:\n",
    "        continue\n",
    "    entity1 = items[2]\n",
    "    entity2 = items[3]\n",
    "    words = items[-1][:-9].split()\n",
    "    words = [word.strip('.') for word in words if len(word) > 0]\n",
    "    if len(words) > max_length:\n",
    "        continue\n",
    "    input_embedding = GetEmbeddingData(entity1, entity2, words, max_length, vec_size, pos_size, model)\n",
    "    train_data[count] = input_embedding\n",
    "    count += 1\n",
    "\n",
    "#     if train_data is None:\n",
    "#         train_data = input_embedding\n",
    "#     else:\n",
    "#         train_data = np.concatenate((train_data, input_embedding),axis = 0)\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "relation_label_np = np.array(relation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/processed_data/nyt_train_label.np', relation_label_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('data/processed_data/nyt_train_data.np', train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count is:  0\n",
      "count is:  10000\n",
      "count is:  20000\n",
      "count is:  30000\n",
      "count is:  40000\n",
      "count is:  50000\n",
      "count is:  60000\n",
      "count is:  70000\n",
      "count is:  80000\n",
      "count is:  90000\n",
      "count is:  100000\n",
      "count is:  110000\n",
      "count is:  120000\n",
      "count is:  130000\n",
      "count is:  140000\n",
      "count is:  150000\n",
      "count is:  160000\n",
      "167387\n"
     ]
    }
   ],
   "source": [
    "test_txt = open('data/nyt/test.txt', 'r')\n",
    "test_lines = [line for line in test_txt]\n",
    "count = 0\n",
    "test_relation_labels = []\n",
    "max_length = 100\n",
    "vec_size = 50\n",
    "pos_size = 5\n",
    "test_data = np.zeros((442506, max_length, pos_size+vec_size))\n",
    "for line in test_lines:\n",
    "    flag = 0\n",
    "    items = line.strip('\\n').split('\\t')\n",
    "    if (count%10000) == 0:\n",
    "        print(\"count is: \", count)\n",
    "    if items[4] in inverse_nyt_rela:\n",
    "        relation_name = inverse_nyt_rela[items[4]]\n",
    "    else:\n",
    "        continue\n",
    "    for (key, relation) in common_relation.items():\n",
    "        nyt_list = relation[2]\n",
    "        for nyt_rela in nyt_list:\n",
    "            if relation_name == (nyt_rela):\n",
    "                relation_id = relation[0]\n",
    "                flag = 1\n",
    "                test_relation_labels.append(relation_id)\n",
    "                break\n",
    "    if flag == 0:\n",
    "        continue\n",
    "    entity1 = items[2]\n",
    "    entity2 = items[3]\n",
    "    words = items[-1][:-9].split()\n",
    "    words = [word.strip('.') for word in words if len(word) > 0]\n",
    "    if len(words) > max_length:\n",
    "        continue\n",
    "    input_embedding = GetEmbeddingData(entity1, entity2, words, max_length, vec_size, pos_size, model)\n",
    "    test_data[count] = input_embedding\n",
    "    count += 1\n",
    "\n",
    "#     if train_data is None:\n",
    "#         train_data = input_embedding\n",
    "#     else:\n",
    "#         train_data = np.concatenate((train_data, input_embedding),axis = 0)\n",
    "print(count)\n",
    "test_data = test_data[0:count-1]\n",
    "test_labels_np = np.array(test_relation_labels)\n",
    "np.save('data/processed_data/nyt_test_label.np', test_labels_np)\n",
    "np.save('data/processed_data/nyt_test_data.np', test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/base/locations/countries/states_provinces_within': '5',\n",
       " '/broadcast/content/location': '39',\n",
       " '/broadcast/producer/location': '38',\n",
       " '/business/business_location/parent_company': '40',\n",
       " '/business/company/advisors': '31',\n",
       " '/business/company/founders': '6',\n",
       " '/business/company/locations': '46',\n",
       " '/business/company/major_shareholders': '37',\n",
       " '/business/company/place_founded': '23',\n",
       " '/business/company_advisor/companies_advised': '20',\n",
       " '/business/person/company': '29',\n",
       " '/business/shopping_center/owner': '32',\n",
       " '/business/shopping_center_owner/shopping_centers_owned': '30',\n",
       " '/film/film/featured_film_locations': '42',\n",
       " '/film/film_festival/location': '52',\n",
       " '/film/film_location/featured_in_films': '51',\n",
       " '/location/administrative_division/country': '24',\n",
       " '/location/br_state/capital': '15',\n",
       " '/location/cn_province/capital': '3',\n",
       " '/location/country/administrative_divisions': '49',\n",
       " '/location/country/capital': '47',\n",
       " '/location/country/languages_spoken': '7',\n",
       " '/location/de_state/capital': '44',\n",
       " '/location/fr_region/capital': '2',\n",
       " '/location/in_state/administrative_capital': '4',\n",
       " '/location/in_state/judicial_capital': '19',\n",
       " '/location/in_state/legislative_capital': '16',\n",
       " '/location/it_region/capital': '10',\n",
       " '/location/jp_prefecture/capital': '41',\n",
       " '/location/location/contains': '48',\n",
       " '/location/mx_state/capital': '26',\n",
       " '/location/neighborhood/neighborhood_of': '1',\n",
       " '/location/province/capital': '27',\n",
       " '/location/us_county/county_seat': '13',\n",
       " '/location/us_state/capital': '12',\n",
       " '/people/deceased_person/place_of_burial': '34',\n",
       " '/people/deceased_person/place_of_death': '9',\n",
       " '/people/ethnicity/geographic_distribution': '35',\n",
       " '/people/ethnicity/included_in_group': '25',\n",
       " '/people/ethnicity/includes_groups': '25',\n",
       " '/people/family/country': '21',\n",
       " '/people/family/members': '11',\n",
       " '/people/person/children': '50',\n",
       " '/people/person/ethnicity': '33',\n",
       " '/people/person/nationality': '28',\n",
       " '/people/person/place_lived': '36',\n",
       " '/people/person/place_of_birth': '8',\n",
       " '/people/person/profession': '45',\n",
       " '/people/person/religion': '18',\n",
       " '/people/place_of_interment/interred_here': '43',\n",
       " '/people/profession/people_with_this_profession': '14',\n",
       " '/sports/sports_team/location': '17',\n",
       " '/sports/sports_team_location/teams': '17',\n",
       " '/time/event/locations': '22',\n",
       " 'NA': '0'}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_nyt_rela"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inverse_nyt_rela['/people/ethnicity/includes_groups'] = '25'\n",
    "inverse_nyt_rela['/sports/sports_team_location/teams'] = '17'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = train_lines[0].strip('\\n').split('\\t')[-1][:-9].split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
