{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from gensim.models import Word2Vec\n",
    "import gensim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/people/deceased_person/place_of_death': 4,\n",
       " '/people/person/place_lived': 3,\n",
       " '/people/person/place_of_birth': 2,\n",
       " 'NA': 0,\n",
       " 'per:origin': 1}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pickle.load(open(\"./unknow_data/relation_dict.pkl\", 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "wiki_relation_map = json.load(open(\"WikipediaWikidataDistantSupervisionAnnotations.v1.0/en.json\", 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word to Vector model.\n",
    "using gensim to implement.\n",
    "save in 'Preprocess_model_pkl/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MySentences(object):\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    " \n",
    "    def __iter__(self):\n",
    "#         for fname in os.listdir(self.dirname):\n",
    "#             for line in open(os.path.join(self.dirname, fname)):\n",
    "#                 yield line.split()\n",
    "         for line in open(self.filename):\n",
    "            temp_sentence = line.split('\\t')[-1]\n",
    "            yield temp_sentence.split()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def GetEntityPos(entity1, entity2, sentence):\n",
    "    pos_1 = 0\n",
    "    pos_2 = 0\n",
    "    for i in range(len(sentence)):\n",
    "        if sentence[i] == entity1:\n",
    "            pos_1 = i\n",
    "        if sentence[i] == entity2:\n",
    "            pos_2 = i\n",
    "    pos_first = min(pos_1, pos_2)\n",
    "    pos_second = pos_1 + pos_2 - pos_first\n",
    "    return [pos_first, pos_second]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LoadFile(filename, max_length, vec_size, pos_size, word_2_vec_model, relation_set):\n",
    "    data_embedding = None\n",
    "    relation_label = []\n",
    "    print(\"Process file:\",filename)\n",
    "    count = 0\n",
    "    for line in open(filename):\n",
    "        if (count%1000) == 0:\n",
    "            print(\"Now the count is: \",count)\n",
    "        count += 1\n",
    "        split_sentce = line.split('\\t')\n",
    "        relation_id = split_sentce[2]\n",
    "        flag = 0\n",
    "        for (key, relation) in relation_set.items():\n",
    "            if relation[1] == relation_id:\n",
    "                relation_id = relation[0]\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            continue\n",
    "        relation_label.append(relation_id)\n",
    "        entity_1 = split_sentce[0]\n",
    "        entity_2 = split_sentce[1]\n",
    "        words = split_sentce[-1].split()\n",
    "        word_embedding = np.zeros((max_length, vec_size))\n",
    "        pos_embedding = np.zeros((max_length, pos_size))\n",
    "        (entity_pos_1, entity_pos_2) = GetEntityPos(entity_1, entity_2, words)\n",
    "        pos_embedding[entity_pos_1] = np.ones(pos_size)\n",
    "        pos_embedding[entity_pos_2] = np.ones(pos_size)\n",
    "        for i in range(len(words)):\n",
    "            word_embedding[i] = word_2_vec_model[words[i]]\n",
    "        input_embedding = np.concatenate((word_embedding, pos_embedding), axis = 1)\n",
    "        input_embedding = input_embedding.reshape(1, max_length, -1)\n",
    "        if data_embedding is None:\n",
    "            data_embedding = input_embedding\n",
    "        else:\n",
    "            data_embedding = np.concatenate((data_embedding, input_embedding), axis = 0)\n",
    "    return (data_embedding,relation_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "is_training = False\n",
    "\n",
    "wiki_data_path = './data/wiki_data/'\n",
    "files = os.listdir(wiki_data_path)\n",
    "wiki_file = './data/wiki_data/filterer-held-out.txt'\n",
    "if is_training:\n",
    "    \n",
    "    # temp_file = open(wiki_file, 'r')\n",
    "    # temp_file_lines = [line for line in temp_file.readlines()]\n",
    "    sentences = MySentences(wiki_file)\n",
    "    model = gensim.models.Word2Vec(sentences, min_count=1, size = 50)\n",
    "    model.save('Preprocess_model_pkl/wiki_vec_model.pkl')\n",
    "else:\n",
    "    model = gensim.models.Word2Vec.load('Preprocess_model_pkl/wiki_vec_model.pkl')\n",
    "relation_set = pickle.load(open('data/common_relations.pkl', 'rb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324704\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for line in open(wiki_file):\n",
    "    count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process file: ./data/wiki_data/filterer-held-out.txt\n",
      "Now the count is:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sun/anaconda/lib/python3.6/site-packages/ipykernel_launcher.py:30: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now the count is:  1000\n",
      "Now the count is:  2000\n",
      "Now the count is:  3000\n",
      "Now the count is:  4000\n",
      "Now the count is:  5000\n",
      "Now the count is:  6000\n",
      "Now the count is:  7000\n",
      "Now the count is:  8000\n",
      "Now the count is:  9000\n",
      "Now the count is:  10000\n",
      "Now the count is:  11000\n",
      "Now the count is:  12000\n",
      "Now the count is:  13000\n",
      "Now the count is:  14000\n",
      "Now the count is:  15000\n",
      "Now the count is:  16000\n",
      "Now the count is:  17000\n",
      "Now the count is:  18000\n",
      "Now the count is:  19000\n",
      "Now the count is:  20000\n",
      "Now the count is:  21000\n",
      "Now the count is:  22000\n",
      "Now the count is:  23000\n",
      "Now the count is:  24000\n",
      "Now the count is:  25000\n",
      "Now the count is:  26000\n",
      "Now the count is:  27000\n",
      "Now the count is:  28000\n",
      "Now the count is:  29000\n",
      "Now the count is:  30000\n",
      "Now the count is:  31000\n",
      "Now the count is:  32000\n",
      "Now the count is:  33000\n",
      "Now the count is:  34000\n",
      "Now the count is:  35000\n",
      "Now the count is:  36000\n",
      "Now the count is:  37000\n",
      "Now the count is:  38000\n",
      "Now the count is:  39000\n",
      "Now the count is:  40000\n",
      "Now the count is:  41000\n",
      "Now the count is:  42000\n",
      "Now the count is:  43000\n",
      "Now the count is:  44000\n",
      "Now the count is:  45000\n",
      "Now the count is:  46000\n",
      "Now the count is:  47000\n",
      "Now the count is:  48000\n",
      "Now the count is:  49000\n",
      "Now the count is:  50000\n",
      "Now the count is:  51000\n",
      "Now the count is:  52000\n",
      "Now the count is:  53000\n",
      "Now the count is:  54000\n",
      "Now the count is:  55000\n",
      "Now the count is:  56000\n",
      "Now the count is:  57000\n",
      "Now the count is:  58000\n",
      "Now the count is:  59000\n",
      "Now the count is:  60000\n",
      "Now the count is:  61000\n",
      "Now the count is:  62000\n",
      "Now the count is:  63000\n",
      "Now the count is:  64000\n",
      "Now the count is:  65000\n",
      "Now the count is:  66000\n",
      "Now the count is:  67000\n",
      "Now the count is:  68000\n",
      "Now the count is:  69000\n",
      "Now the count is:  70000\n",
      "Now the count is:  71000\n",
      "Now the count is:  72000\n",
      "Now the count is:  73000\n",
      "Now the count is:  74000\n",
      "Now the count is:  75000\n",
      "Now the count is:  76000\n",
      "Now the count is:  77000\n",
      "Now the count is:  78000\n",
      "Now the count is:  79000\n",
      "Now the count is:  80000\n",
      "Now the count is:  81000\n",
      "Now the count is:  82000\n",
      "Now the count is:  83000\n",
      "Now the count is:  84000\n",
      "Now the count is:  85000\n",
      "Now the count is:  86000\n",
      "Now the count is:  87000\n",
      "Now the count is:  88000\n",
      "Now the count is:  89000\n",
      "Now the count is:  90000\n",
      "Now the count is:  91000\n",
      "Now the count is:  92000\n",
      "Now the count is:  93000\n",
      "Now the count is:  94000\n",
      "Now the count is:  95000\n",
      "Now the count is:  96000\n",
      "Now the count is:  97000\n",
      "Now the count is:  98000\n",
      "Now the count is:  99000\n",
      "Now the count is:  100000\n",
      "Now the count is:  101000\n",
      "Now the count is:  102000\n",
      "Now the count is:  103000\n",
      "Now the count is:  104000\n",
      "Now the count is:  105000\n",
      "Now the count is:  106000\n",
      "Now the count is:  107000\n",
      "Now the count is:  108000\n",
      "Now the count is:  109000\n",
      "Now the count is:  110000\n",
      "Now the count is:  111000\n",
      "Now the count is:  112000\n",
      "Now the count is:  113000\n",
      "Now the count is:  114000\n",
      "Now the count is:  115000\n",
      "Now the count is:  116000\n",
      "Now the count is:  117000\n",
      "Now the count is:  118000\n",
      "Now the count is:  119000\n",
      "Now the count is:  120000\n",
      "Now the count is:  121000\n",
      "Now the count is:  122000\n",
      "Now the count is:  123000\n",
      "Now the count is:  124000\n",
      "Now the count is:  125000\n",
      "Now the count is:  126000\n",
      "Now the count is:  127000\n",
      "Now the count is:  128000\n",
      "Now the count is:  129000\n",
      "Now the count is:  130000\n",
      "Now the count is:  131000\n",
      "Now the count is:  132000\n",
      "Now the count is:  133000\n",
      "Now the count is:  134000\n",
      "Now the count is:  135000\n",
      "Now the count is:  136000\n",
      "Now the count is:  137000\n",
      "Now the count is:  138000\n",
      "Now the count is:  139000\n",
      "Now the count is:  140000\n",
      "Now the count is:  141000\n",
      "Now the count is:  142000\n",
      "Now the count is:  143000\n",
      "Now the count is:  144000\n",
      "Now the count is:  145000\n",
      "Now the count is:  146000\n",
      "Now the count is:  147000\n",
      "Now the count is:  148000\n"
     ]
    }
   ],
   "source": [
    "data = LoadFile(wiki_file, 100, vec_size=50, pos_size=5, word_2_vec_model=model, relation_set=relation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data = np.load('data/processed_data/wiki_held-out_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(324704, 100, 55)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
